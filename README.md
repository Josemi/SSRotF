# üå≥ Semi-Supervised Rotation Forest üå≥  
 
Rotation Forest (RotF) is a popular tree-based ensemble method that has gained a deserved fame in the machine learning community. Its effectiveness is based on the rotation of the data before the base estimators training. This process increases the diversity of the ensemble, which in turn improves its generalization capabilities. Rotation Forest is a supervised learning (SL) method that should be trained with a sufficient number of labeled instances, in order to obtain a robust model.
 
> Rodr√≠guez, J. J., Kuncheva, L. I., & Alonso, C. J. (2006). Rotation forest: A new classifier ensemble method. IEEE Transactions on Pattern Analysis and Machine Intelligence, 28(10), 1619‚Äì1630. [IEEE](https://doi.org/10.1109/TPAMI.2006.211).
 
The field of machine learning has witnessed a surge of development over the last decades, with the proliferation of novel techniques such as semi-supervised learning (SSL). SSL lies between supervised and unsupervised learning. It allows the solution of classification and regression problems characteristic of supervised learning, while also allowing for the acquisition of information from unlabeled instances.  
 
This paper presents a semi-supervised version of the ensemble method Rotation Forest for tabular data, called Semi-Supervised Rotation Forest (SSRotF). This semi-supervised version includes two main modifications that allow Rotation Forest to use unlabeled data, thereby improving its performance.  
 
## üî¨ Experimentation  
 
In order to demonstrate the performance of the proposed method and to extend the experimentation, tests were conducted using 54 different UCI datasets. This experimentation also includes a meta-learning analysis in which 16 datasets were selected, for which the good results obtained lead us to believe that they verify some assumptions of the semi-supervised learning, making them more suitable for this and future experimentation. This experimentation demonstrates the capabilities of Rotation Forest, even in situations with few labeled instances, and highlights the improvement of the proposed semi-supervised version.  
 
## üìÇ Repository Structure  
 
This repository contains the following files:  
 
### üîπ RotationForestSSL.py  
This file implements *Semi-Supervised Rotation Forest (SSRotF)*, introducing two modifications to the original Rotation Forest algorithm:
1. *Modified PCA transformation* ‚Üí PCA is applied by incorporating a subset of the unlabeled instances, thereby increasing the model‚Äôs diversity.  
2. *SSLTree as base estimator* ‚Üí Instead of using traditional decision trees, SSRotF employs *SSLTree*, a decision tree that is intrinsically semi-supervised.  
 
### üîπ SSLTree.py  
This file contains the implementation of *SSLTree*, a CART decision tree model specifically designed for semi-supervised learning.  
Unlike standard decision trees, *SSLTree incorporates unlabeled instances during its construction*, allowing it to extract additional information from the data distribution.
 
This method is based on the impurity calculation described in:
> Levatiƒá, J., Ceci, M., Kocev, D., & D≈æeroski, S. (2017). Semi-supervised classification trees. Journal of Intelligent Information Systems, 49, 461‚Äì486. [Springer](https://doi.org/10.1007/s10844-017-0457-4).  
 
### üîπ experiments.py  
This script provides the *experimental framework* for evaluating SSRotF and comparing it with other models:
 
- *Cross-validation with repetition* ‚Üí Each experiment runs multiple repetitions, and within each repetition, cross-validation is applied. This ensures robust evaluation by reducing the impact of randomness. 
- The experiments are executed by repetition, within each repetition by dataset, within each dataset by fold, and within each fold by label proportion. Each of these configurations is stored and then executed using a pool of jobs in multiprocessing.
- The utilities used throughout the script (*utils* package) must be requested, as they include code used in multiple other experiments and are considered for private use. The utils package is primarily used for data collection and handling datasets (p.e, metrics calculation).

### üîπ results.pdf  
A pdf file with the results of the above experiments, for each label proportion and metric.

## ‚öôÔ∏è Execution Example
```Python
# Imports
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sslearn.model_selection import artificial_ssl_dataset
from RotationForestSSL import RotationForestSSLClassifier
from SSLTree import SSLTree

# Load iris
X,y = load_iris(return_X_y=True)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Remove labels
X_train_ssl, y_train_ssl, X_unlabeled, y_unlabeled = artificial_ssl_dataset(X_train, y_train, 0.1)

# Train SSRotF
ssrotf = RotationForestSSLClassifier(n_estimators=100, base_estimator=SSLTree(max_depth=100, w=0.85, max_features="sqrt"))
ssrotf.fit(X_train_ssl, y_train_ssl)

# Predict
y_pred = ssrotf.predict(X_test)
```
 
## üë• Authors  
 
- Jos√© Miguel Ram√≠rez-Sanz  
- David Mart√≠nez-Acha  
- √Ålvar Arnaiz-Gonz√°lez  
- C√©sar Garc√≠a-Osorio  
- Juan J. Rodr√≠guez  
 
### üìå Cite this software as:  
Under review
